{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from Step 2 has been exported and saved as cleaned_loans_2007.csv to be used for the final step in making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38708 entries, 0 to 38707\n",
      "Data columns (total 38 columns):\n",
      "loan_amnt                              38708 non-null float64\n",
      "int_rate                               38708 non-null float64\n",
      "installment                            38708 non-null float64\n",
      "emp_length                             38708 non-null int64\n",
      "annual_inc                             38708 non-null float64\n",
      "loan_status                            38708 non-null int64\n",
      "dti                                    38708 non-null float64\n",
      "delinq_2yrs                            38708 non-null float64\n",
      "inq_last_6mths                         38708 non-null float64\n",
      "open_acc                               38708 non-null float64\n",
      "pub_rec                                38708 non-null float64\n",
      "revol_bal                              38708 non-null float64\n",
      "revol_util                             38708 non-null float64\n",
      "total_acc                              38708 non-null float64\n",
      "home_ownership_MORTGAGE                38708 non-null float64\n",
      "home_ownership_NONE                    38708 non-null float64\n",
      "home_ownership_OTHER                   38708 non-null float64\n",
      "home_ownership_OWN                     38708 non-null float64\n",
      "home_ownership_RENT                    38708 non-null float64\n",
      "verification_status_Not Verified       38708 non-null float64\n",
      "verification_status_Source Verified    38708 non-null float64\n",
      "verification_status_Verified           38708 non-null float64\n",
      "purpose_car                            38708 non-null float64\n",
      "purpose_credit_card                    38708 non-null float64\n",
      "purpose_debt_consolidation             38708 non-null float64\n",
      "purpose_educational                    38708 non-null float64\n",
      "purpose_home_improvement               38708 non-null float64\n",
      "purpose_house                          38708 non-null float64\n",
      "purpose_major_purchase                 38708 non-null float64\n",
      "purpose_medical                        38708 non-null float64\n",
      "purpose_moving                         38708 non-null float64\n",
      "purpose_other                          38708 non-null float64\n",
      "purpose_renewable_energy               38708 non-null float64\n",
      "purpose_small_business                 38708 non-null float64\n",
      "purpose_vacation                       38708 non-null float64\n",
      "purpose_wedding                        38708 non-null float64\n",
      "term_ 36 months                        38708 non-null float64\n",
      "term_ 60 months                        38708 non-null float64\n",
      "dtypes: float64(36), int64(2)\n",
      "memory usage: 11.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "loans = pd.read_csv('cleaned_loans_2007.csv')\n",
    "loans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into predicting loan_status with machine learning, let's recap our first steps when we started cleaning the Lending Club dataset. \n",
    "\n",
    "We established that this is a binary classification problem in the first mission of this course, and we converted the loan_status column to 0s and 1s as a result. Before diving in and selecting an algorithm to apply to the data, we should select an error metric.\n",
    "\n",
    "An error metric will help us figure out when our model is performing well, and when it's performing poorly. To tie error metrics all the way back to the original question we wanted to answer, let's say we're using a machine learning model to predict whether or not we should fund a loan on the Lending Club platform. Our objective in this is to make money -- we want to fund enough loans that are paid off on time to offset our losses from loans that aren't paid off. An error metric will help us determine if our algorithm will make us money or lose us money.\n",
    "\n",
    "In this case, we're primarily concerned with false positives and false negatives. Both of these are different types of misclassifications. With a false positive, we predict that a loan will be paid off on time, but it actually isn't. With a false negative, we predict that a loan won't be paid off on time, but it actually would be paid off on time. Both cases have to be taken into consideration so the firm does not lose money.\n",
    "\n",
    "Here's a diagram to simplify the concepts:\n",
    "![img](tab.jpg)\n",
    "\n",
    "In the loan_status and prediction columns, a 0 means that the loan wouldn't be paid off on time, and a 1 means that it would.\n",
    "\n",
    "Since we're viewing this problem from the standpoint of a conservative investor, we need to treat false positives differently than false negatives. A conservative investor would want to minimize risk, and avoid false positives as much as possible. They'd be more okay with missing out on opportunities (false negatives) than they would be with funding a risky loan (false positives).\n",
    "\n",
    "Let's calculate false positives and true positives in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "\n",
    "# Predict that all loans will be paid off on time.\n",
    "predictions = pd.Series(numpy.ones(loans.shape[0]))\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last screen, you may have noticed that both fpr and tpr were 1. This is because we predicted 1 for each row. This means that we correctly identified all of the good loans (true positive rate), but we also incorrectly identified all of the bad loans (false positive rate). Now that we've setup error metrics, we can move on to making predictions using a machine learning algorithm.\n",
    "\n",
    "As we saw in the first screen of the mission, our cleaned dataset contains 41 columns, all of which are either the int64 or the float64 data type. There are no null values in any of the columns. This implies we can now apply any machine learning algorithm to our dataset. \n",
    "\n",
    "A good first algorithm to apply to binary classification problems is logistic regression, for the following reasons:\n",
    "* it's quick to train and we can iterate more quickly,\n",
    "* it's less prone to overfitting than more complex models like decision trees,\n",
    "* it's easy to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.145757982846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LogisticRegression()\n",
    "cols = loans.columns\n",
    "train_cols = cols.drop(\"loan_status\")\n",
    "features = loans[train_cols]\n",
    "target = loans[\"loan_status\"]\n",
    "lr.fit(features, target)\n",
    "predictions = lr.predict(features)\n",
    "print(mean_squared_error(loans[\"loan_status\"],predictions))\n",
    "# notce the very low error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions above were overfit because we generated predictions using the same data that we trained our model on. \n",
    "\n",
    "**In order to get a realistic depiction of the accuracy of the model, let's perform k-fold cross validation.**\n",
    "\n",
    "Once we have cross validated predictions, we can compute the true positive and false positive rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9989121566494424\n",
      "0.9967943009795192\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "lr = LogisticRegression()\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Calculate Sensitivity \n",
    "tpr = tp  / (tp + fn)\n",
    "\n",
    "# Calculate Specificity \n",
    "fpr = fp  / (fp + tn)\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalizing the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the last screen, our fpr and tpr are around what we'd expect if the model was predicting all ones. \n",
    "\n",
    "Unfortunately, even through we're not using accuracy as an error metric, the classifier is, and it isn't accounting for the imbalance in the classes. \n",
    "\n",
    "There are a few ways to get a classifier to correct for imbalanced classes. The two main ways are:\n",
    "* Use oversampling and undersampling to ensure that the classifier gets input that has a balanced number of each class.\n",
    "* Tell the classifier to penalize misclassifications of the less prevalent class more than the other class.\n",
    "\n",
    "We'll look into oversampling and undersampling first. They involve taking a sample that contains equal numbers of rows where loan_status is 0, and where loan_status is 1. This way, the classifier is forced to make actual predictions, since predicting all 1s or all 0s will only result in 50% accuracy at most.\n",
    "\n",
    "The downside of this technique is that since it has to preserve an equal ratio, you have to either:\n",
    "* Throw out many rows of data. If we wanted equal numbers of rows where loan_status is 0 and where loan_status is 1, one way we could do that is to delete rows where loan_status is 1.\n",
    "* Copy rows multiple times. One way to equalize the 0s and 1s is to copy rows where loan_status is 0.\n",
    "* Generate fake data. One way to equalize the 0s and 1s is to generate new rows where loan_status is 0.\n",
    "\n",
    "Unfortunately, none of these techniques are especially easy. The second method we mentioned earlier, telling the classifier to penalize certain rows more, is actually much easier to implement using scikit-learn.\n",
    "\n",
    "We can do this by setting the class_weight parameter to balanced when creating the LogisticRegression instance. This tells scikit-learn to penalize the misclassification of the minority class during the training process. The penalty means that the logistic regression classifier pays more attention to correctly classifying rows where loan_status is 0. This lowers accuracy when loan_status is 1, but raises accuracy when loan_status is 0.\n",
    "\n",
    "By setting the class_weight parameter to balanced, the penalty is set to be inversely proportional to the class frequencies. You can read more about the parameter here. This would mean that for the classifier, correctly classifying a row where loan_status is 0 is 6 times more important than correctly classifying a row where loan_status is 1.\n",
    "\n",
    "We can repeat the cross validation procedure we performed in the last screen, but with the **class_weight parameter set to balanced**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6579034841205089\n",
      "0.38290293855743546\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual penalties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We significantly improved the false positive rate in the last screen by balancing the classes, which reduced true positive rate. Our true positive rate is now around 67%, and our false positive rate is around 40%. From a conservative investor's standpoint, it's reassuring that the false positive rate is lower because it means that we'll be able to do a better job at avoiding bad loans than if we funded everything. However, we'd only ever decide to fund 67% of the total loans (true positive rate), so we'd immediately reject a good amount of loans.\n",
    "\n",
    "We can try to lower the false positive rate further by assigning a harsher penalty for misclassifying the negative class. While setting class_weight to balanced will automatically set a penalty based on the number of 1s and 0s in the column, we can also set a manual penalty. In the last screen, the penalty scikit-learn imposed for misclassifying a 0 would have been around 5.89 (since there are 5.89 times as many 1s as 0s).\n",
    "\n",
    "We can also specify a penalty manually if we want to adjust the rates more. To do this, we need to pass in a dictionary of penalty values to the class_weight parameter:\n",
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "The above dictionary will impose a penalty of 10 for misclassifying a 0, and a penalty of 1 for misclassifying a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24005076602302602\n",
      "0.09029385574354408\n"
     ]
    }
   ],
   "source": [
    "penalty = {\n",
    "    0: 10,\n",
    "    1: 1\n",
    "}\n",
    "\n",
    "lr = LogisticRegression(class_weight=penalty)\n",
    "predictions = cross_val_predict(lr, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like assigning manual penalties lowered the false positive rate to 9%, and thus lowered our risk. Note that this comes at the expense of true positive rate. While we have fewer false positives, we're also missing opportunities to fund more loans and potentially make more money. Given that we're approaching this as a conservative investor, this strategy makes sense, but it's worth keeping in mind the tradeoffs.\n",
    "\n",
    "While we could tweak the penalties further, it's best to try a different model, for larger potential false positive rate gains. We can always loop back and iterate on the penalties later.\n",
    "\n",
    "Let's try a more complex algorithm, random forest. We learned about random forests in a previous mission, and constructed our own model. Random forests are able to work with nonlinear data, and learn complex conditionals. Logistic regressions are only able to work with linear data. Training a random forest algorithm may enable us to get more accuracy due to columns that correlate nonlinearly with loan_status.\n",
    "\n",
    "We can use the RandomForestClassifer class from scikit-learn to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9708699725017376\n",
      "0.9271593944790739\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=1)\n",
    "predictions = cross_val_predict(rf, features, target, cv=3)\n",
    "predictions = pd.Series(predictions)\n",
    "\n",
    "# False positives.\n",
    "fp_filter = (predictions == 1) & (loans[\"loan_status\"] == 0)\n",
    "fp = len(predictions[fp_filter])\n",
    "\n",
    "# True positives.`\n",
    "tp_filter = (predictions == 1) & (loans[\"loan_status\"] == 1)\n",
    "tp = len(predictions[tp_filter])\n",
    "\n",
    "# False negatives.\n",
    "fn_filter = (predictions == 0) & (loans[\"loan_status\"] == 1)\n",
    "fn = len(predictions[fn_filter])\n",
    "\n",
    "# True negatives\n",
    "tn_filter = (predictions == 0) & (loans[\"loan_status\"] == 0)\n",
    "tn = len(predictions[tn_filter])\n",
    "\n",
    "# Rates\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(tpr)\n",
    "print(fpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, using a random forest classifier didn't improve our false positive rate. The model is likely weighting too heavily on the 1 class, and still mostly predicting 1s. We could fix this by applying a harsher penalty for misclassifications of 0s.\n",
    "\n",
    "Ultimately, our best model had a false positive rate of 9%, and a true positive rate of 24%. For a conservative investor, this means that they make money as long as the interest rate is high enough to offset the losses from 9% of borrowers defaulting, and that the pool of 24% of borrowers is large enough to make enough interest money to offset the losses.\n",
    "\n",
    "If we had randomly picked loans to fund, borrowers would have defaulted on 14.5% of them, and our model is better than that, although we're excluding more loans than a random strategy would. Given this, there's still quite a bit of room to improve:\n",
    "\n",
    "We can tweak the penalties further.\n",
    "We can try models other than a random forest and logistic regression.\n",
    "We can use some of the columns we discarded to generate better features.\n",
    "We can ensemble multiple models to get more accurate predictions.\n",
    "We can tune the parameters of the algorithm to achieve higher performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
