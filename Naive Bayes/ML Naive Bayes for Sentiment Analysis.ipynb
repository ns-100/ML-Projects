{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with a CSV file containing movie reviews. **Each row contains the text of the review, as well as a number indicating whether the tone of the review is positive(1) or negative(-1)**.\n",
    "\n",
    "We want to predict whether a review is negative or positive, based on the text alone. To do this, we will train an algorithm using the reviews and classifications in train.csv, and then make predictions on the reviews in test.csv. We'll be able to calculate our error using the actual classifications in test.csv to see how good our predictions are.\n",
    "\n",
    "We'll use Naive Bayes for our classification algorithm. A Naive Bayes classifier (based on Bayes' theorem) works by figuring out how likely data attributes are to be associated with a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Word Counts\n",
    "\n",
    "We are trying to determine if we should classify a data row as negative or positive. We have to calculate the probabilities of each classification, and the probabilities of each feature falling into each classification.\n",
    "\n",
    "All we have is one long string, but we can generate features from it. The easiest way to generate features from text is to split the text up into words. Each word in a movie review will then be a feature that we can work with. To do this, we will split the reviews based on whitespace.\n",
    "\n",
    "Then, we will determine word frequency in the negative reviews, and positive reviews. Eventually, we'll use the word frequency to compute the probability that a new review will belong to one class versus the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot : two teen couples go to a church party drink and then drive . they get into an accident . one of the guys dies but his girlfriend continues to see him in her life and has nightmares . what\\'s the deal ? watch the movie and \" sorta \" find out . . . critique : a mind-fuck movie for the teen generation that touches on a very cool idea but presents it in a very bad package . which is what makes this review an even harder one to write since i generally applaud films which attempt',\n",
       " '-1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Counter class allows us to count how many times items occur in a list\n",
    "from collections import Counter\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# Read in the training data\n",
    "with open(\"train.csv\", 'r') as file:\n",
    "    reviews = list(csv.reader(file))\n",
    "    \n",
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative text sample: plot : two teen couples go to a church party drink and then drive . they get into an accident . one \n",
      "Positive text sample: films adapted from comic books have had plenty of success whether they're about superheroes ( batman\n"
     ]
    }
   ],
   "source": [
    "def get_text(reviews, score):\n",
    "    # convert to Lowercase \n",
    "    return \" \".join([r[0].lower() for r in reviews if r[1] == str(score)])\n",
    "\n",
    "def count_text(text):\n",
    "    # Split text into words based on whitespace. words is a list\n",
    "    words = re.split(\"\\s+\", text)\n",
    "    # Count occurrence of each word and return as Counter object\n",
    "    # sample of what this looks like - Counter({'the': 3181, '.': 2752, 'a': 1941, 'of': 1649,\n",
    "    return Counter(words)\n",
    "\n",
    "negative_text = get_text(reviews, -1)\n",
    "positive_text = get_text(reviews, 1)\n",
    "\n",
    "# Generate word counts for negative tone. \n",
    "negative_counts = count_text(negative_text)\n",
    "\n",
    "# Generate word counts for positive tone\n",
    "positive_counts = count_text(positive_text)\n",
    "\n",
    "print(\"Negative text sample: {0}\".format(negative_text[:100]))\n",
    "print(\"Positive text sample: {0}\".format(positive_text[:100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions About Review Classifications\n",
    "\n",
    "Now that we have the word counts, we just need to convert them to probabilities and multiply them out to predict the classifications.\n",
    "\n",
    "Let's say we wanted to find the probability that the review \"didn't like it\" expresses a negative sentiment. We would find the total number of times the word \"didn't\" occurred in the negative reviews, and divide it by the total number of words in the negative reviews to get the probability of x given y. We would then do the same for \"like\" and \"it\". We would multiply all three probabilities, and then multiply by the probability of any document expressing a negative sentiment to get our final probability that the sentence expresses negative sentiment.\n",
    "\n",
    "We would do the same for positive sentiment. Then, whichever probability is greater would be the class that the algorithm assigns the review to.\n",
    "\n",
    "To accomplish all of this, we'll need to compute the probabilities of each class occurring in the data, and then write a function that computes the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling an actual negative review:\n",
      "\n",
      "Review: it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . based on the late 1960's television show by the same name the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . however things go wrong as evidence gets stolen and they are immediately under suspicion . of course the ads make it seem like so much more . quick cuts cool music claire dane's nice hair and cute outfits car\n",
      "Rating: -1\n",
      "Negative prediction: 5.327907949310682e-234\n",
      "Positive prediction: 2.0820582627346563e-241\n",
      "\n",
      "Sampling an actual positive review:\n",
      "\n",
      "Review: you've got mail works alot better than it deserves to . in order to make the film a success all they had to do was cast two extremely popular and attractive stars have them share the screen for about two hours and then collect the profits . no real acting was involved and there is not an original or inventive bone in it's body ( it's basically a complete re-shoot of the shop around the corner only adding a few modern twists ) . essentially it goes against and defies all concepts of go\n",
      "Rating: 1\n",
      "Negative prediction: 1.0213603625672054e-233\n",
      "Positive prediction: 3.827657302041472e-231\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def get_y_count(score):\n",
    "    # Compute the count of each classification occurring in the data\n",
    "    return len([r for r in reviews if r[1] == str(score)])\n",
    "\n",
    "# We'll use these counts for smoothing when computing the prediction\n",
    "positive_review_count = get_y_count(1)\n",
    "negative_review_count = get_y_count(-1)\n",
    "\n",
    "# These are the class probabilities \n",
    "prob_positive = positive_review_count / len(reviews)\n",
    "prob_negative = negative_review_count / len(reviews)\n",
    "\n",
    "def make_class_prediction(text, counts, class_prob, class_count):\n",
    "    prediction = 1\n",
    "    text_counts = Counter(re.split(\"\\s+\", text))\n",
    "    for word in text_counts:\n",
    "        # For every word in the text, we get the number of times that word occurred in the reviews \n",
    "        # for a given class, add 1 to smooth the value, and divide by the total number of words in \n",
    "        # the class (plus the class_count, also to smooth the denominator)\n",
    "        \n",
    "        # Smoothing ensures that we don't multiply the prediction by 0 if the word didn't exist in \n",
    "        # the training data\n",
    "        \n",
    "        # We also smooth the denominator counts to keep things even\n",
    "        prediction *=  text_counts.get(word) * ((counts.get(word, 0) + 1) / \n",
    "                       (sum(counts.values()) + class_count))\n",
    "    # Now we multiply by the probability of the class existing in the documents\n",
    "    return prediction * class_prob\n",
    "\n",
    "# Now we can generate probabilities for the classes our reviews belong to\n",
    "# The probabilities themselves aren't very useful -- we make our classification decision based on \n",
    "# which value is greater\n",
    "print(\"Sampling an actual negative review:\\n\")\n",
    "print(\"Review: {0}\".format(reviews[2][0]))\n",
    "print(\"Rating: {0}\".format(reviews[2][1]))\n",
    "print(\"Negative prediction: {0}\".format(make_class_prediction(reviews[2][0], negative_counts, prob_negative, negative_review_count)))\n",
    "print(\"Positive prediction: {0}\".format(make_class_prediction(reviews[2][0], positive_counts, prob_positive, positive_review_count)))\n",
    "\n",
    "print(\"\\nSampling an actual positive review:\\n\")\n",
    "print(\"Review: {0}\".format(reviews[710][0]))\n",
    "print(\"Rating: {0}\".format(reviews[710][1]))\n",
    "print(\"Negative prediction: {0}\".format(make_class_prediction(reviews[710][0], negative_counts, prob_negative, negative_review_count)))\n",
    "print(\"Positive prediction: {0}\".format(make_class_prediction(reviews[710][0], positive_counts, prob_positive, positive_review_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Test Set\n",
    "\n",
    "Now that we can make predictions, let's predict the probabilities for the reviews in test.csv. We may get misleadingly good results if we predict on the reviews in train.csv, because we used that data set to generate the probabilities in the first place (so the algorithm has prior knowledge about the data it's predicting on).\n",
    "\n",
    "Getting good results on the training set could mean that our model is overfit, and just picking up random noise. Testing on a set the model wasn't trained with is the only way to tell if it's performing properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def make_decision(text, make_class_prediction):\n",
    "    # Compute the negative and positive probabilities\n",
    "    negative_prediction = make_class_prediction(text, negative_counts, prob_negative, negative_review_count)\n",
    "    positive_prediction = make_class_prediction(text, positive_counts, prob_positive, positive_review_count)\n",
    "\n",
    "    # We assign a classification based on which probability is greater\n",
    "    if negative_prediction > positive_prediction:\n",
    "      return -1\n",
    "    return 1\n",
    "\n",
    "with open(\"test.csv\", 'r') as file:\n",
    "    test = list(csv.reader(file))\n",
    "\n",
    "predictions = [make_decision(r[0], make_class_prediction) for r in test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Prediction Error\n",
    "\n",
    "Now that we know the predictions, we'll compute error using the area under the ROC curve. This will tell us how \"good\" the model is; closer to 1 means that the model is better.\n",
    "\n",
    "Computing error is a very important measure of whether your model is \"good,\" and when it's getting better or worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the predictions: 0.680701754385965\n"
     ]
    }
   ],
   "source": [
    "actual = [int(r[1]) for r in test]\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate the ROC curve using scikits-learn\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve\n",
    "# The closer to 1 it is, the \"better\" the predictions\n",
    "print(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Faster Way to Make Predictions\n",
    "\n",
    "There are a lot of extensions we could add to this algorithm to make it perform better. We could look at n-grams instead of unigrams, for example. We could also remove punctuation and other non-characters. We could remove stop words, or perform stemming or lemmatization.\n",
    "\n",
    "Also an easier way to use Naive Bayes is to use the implementation in scikit-learn. Scikit-learn is a Python machine learning library that contains implementations of all the common machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate counts from text using a vectorizer  \n",
    "# We can choose from other available vectorizers, and set many different options\n",
    "# This code performs our step of computing word counts\n",
    "vectorizer = CountVectorizer(stop_words='english', max_df=.05)\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "\n",
    "# Fit a Naive Bayes model to the training data\n",
    "# This will train the model using the word counts we computed and the existing classifications in the training set\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features\n",
    "predictions = nb.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of the predictions: 0.635500515995872\n"
     ]
    }
   ],
   "source": [
    "# Compute the error using auc\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "\n",
    "# Measure the area under the curve\n",
    "# The closer to 1 it is, the \"better\" the predictions\n",
    "print(\"AUC of the predictions: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63451776649746194"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using mean\n",
    "import numpy as np\n",
    "target_review = [int(r[1]) for r in test]\n",
    "np.mean(predictions == target_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see if we can do better with a linear support vector machine (SVM), which is widely regarded as one of the best text classification algorithms (although it’s also a bit slower than naïve Bayes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63451776649746194"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(train_features, [int(r[1]) for r in reviews])\n",
    "predictions = nb.predict(test_features)\n",
    "np.mean(predictions == target_review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
